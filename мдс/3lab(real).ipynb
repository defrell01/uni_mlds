{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "335ea683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10e86797",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, x, y):\n",
    "        self.intercept = np.ones((x.shape[0], 1))\n",
    "        self.x = np.concatenate((self.intercept, x), axis=1)\n",
    "        self.weight = np.zeros(self.x.shape[1])\n",
    "        self.y = y\n",
    "        \n",
    "    @staticmethod\n",
    "    def sigmoid(x, weight):\n",
    "        z = np.dot(x, weight)\n",
    "        sigma = 1 / (1 + np.exp(-z))\n",
    "        return sigma\n",
    "    \n",
    "    def loss(self, y):\n",
    "        n = y.shape[0]\n",
    "        h = self.sigmoid(self.x, self.weight)\n",
    "        if True:\n",
    "            try:\n",
    "                los = 1 / n * (-y.T * np.log(h) - (1 - y).T * np.log(1 - h))\n",
    "                return los\n",
    "            except ValueError:\n",
    "                print('e')\n",
    "    \n",
    "    def gradient_descent(self, y):\n",
    "        n = y.shape[0]\n",
    "        grad = 1 / n * self.x.transpose() @(self.sigmoid(self.x, self.weight) - y)\n",
    "        return grad\n",
    "\n",
    "    def fit(self, lr, iterations):\n",
    "        for i in range(iterations):\n",
    "            dw = self.gradient_descent(self.y)\n",
    "            self.weight -= np.dot(lr, dw)\n",
    "        \n",
    "        return print('Done')\n",
    "    \n",
    "#     def predict(self, x, x_new, treshold):\n",
    "#         x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "#         result = self.sigmoid(x_new, self.weight)\n",
    "#         result = result >= treshold\n",
    "#         ypred = np.zeros(result.shape[0])\n",
    "#         for i in range(len(ypred)):\n",
    "#             if result[i]:\n",
    "#                 ypred[i] = 1\n",
    "#             else:\n",
    "#                 continue\n",
    "#         return ypred\n",
    "    \n",
    "    def predict(self, x_new , treshold):\n",
    "        x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "        result = self.sigmoid(x_new, self.weight)\n",
    "        result = result >= treshold\n",
    "        y_pred = np.zeros(result.shape[0])\n",
    "        for i in range(len(y_pred)):\n",
    "            if result[i] == True:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                continue\n",
    "        return y_pred\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7aaa3ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18639/4083371330.py:11: RuntimeWarning: overflow encountered in exp\n",
      "  sigma = 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Accuracy => [0.92091388]\n",
      "0:00:05.002029\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "a = data.data\n",
    "b = data.target\n",
    "regressor = LogisticRegression(a,b)\n",
    "regressor.fit(0.1, 5000)\n",
    "y_pred = regressor.predict(a, 0.5)\n",
    "print('Accuracy => {}'.format(sum(y_pred == b)/b.shape))\n",
    "start_time = datetime.now()\n",
    "time.sleep(5)\n",
    "print(datetime.now() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd76d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import exception\n",
    "import math\n",
    "from random import randint\n",
    "from typing import Type\n",
    "\n",
    "\n",
    "class Matrix:\n",
    "\n",
    "    def __init__(self, n, m):\n",
    "        self.matrix = self.get_matrix(n, m)\n",
    "\n",
    "    def get_matrix(self, n, m):\n",
    "        # if math.isnan(int(n)) or math.isnan(int(m)):\n",
    "        #     return 'e'\n",
    "        try:\n",
    "            if n<0 or m<0:\n",
    "                return 'e'\n",
    "            matrix = [[None for j in range(m)] for i in range(n)]\n",
    "            for i in range(len(matrix)):\n",
    "                for j in range(len(matrix[i])):\n",
    "                    matrix[i][j] = randint(-10, 10)\n",
    "            return matrix\n",
    "        except TypeError:\n",
    "            return 'e'\n",
    "    def get_readable_matrix_string(self, matrix):\n",
    "        strings = []\n",
    "        for row in matrix:\n",
    "            strings.append(str(row))\n",
    "        return '\\n'.join(strings)\n",
    "\n",
    "    # Магические методы\n",
    "\n",
    "    # Определяет поведение при вызове функции str() в т.ч. и print()\n",
    "    def __str__(self):\n",
    "        return self.get_readable_matrix_string(self.matrix)\n",
    "\n",
    "    # Возвращает кол-во элементов\n",
    "    def __len__(self):\n",
    "        return len(self.matrix)\n",
    "    \n",
    "    # Определяет поведение при доступе к элементу класса\n",
    "    def __getitem__(self, item):\n",
    "        return self.matrix[item]\n",
    "    \n",
    "    # Определяет поведение при умножении\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, Matrix):\n",
    "            return self.get_readable_matrix_string(self.multiply(other))\n",
    "        return self.get_readable_matrix_string([[num*other for num in row] for row in self.matrix])\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return self.getSummarize(other)\n",
    "    \n",
    "    def __sub__ (self, other):\n",
    "        return self.getSubtraction(other)\n",
    "    \n",
    "    # Магические методы\n",
    "\n",
    "    ## Функция трнаспонирования с помощью zip (internal)\n",
    "    def transpose(self, matrix):\n",
    "        return [list(i) for i in zip(*matrix)]\n",
    "\n",
    "    ## Возвращаем транспонированную в нужном виде\n",
    "    def getTranspose(self):\n",
    "        return self.get_readable_matrix_string(self.transpose(self.matrix))\n",
    "\n",
    "    ## Преобразование в транспонированную \n",
    "    def doTranspose(self):\n",
    "        self.matrix = self.transpose(self.matrix)\n",
    "\n",
    "    def multiply(self, matrix):\n",
    "        \n",
    "        # if len(self.matrix[0]) != len(matrix):\n",
    "        #     correct = True\n",
    "        try:\n",
    "            result = [[0 for j in range(len(matrix[i]))]\n",
    "                    for i in range(len(self.matrix))]\n",
    "            for i in range(len(self.matrix)):\n",
    "                for j in range(len(matrix[0])):\n",
    "                    for k in range(len(matrix)):\n",
    "                        result[i][j] += self.matrix[i][k] * matrix[k][j]\n",
    "            return result\n",
    "        except IndexError:\n",
    "            return 'e'\n",
    "\n",
    "    def getMultiply(self, matrix):\n",
    "        return self.get_readable_matrix_string(self.multiply(matrix))\n",
    "\n",
    "    def summarize(self, matrix):\n",
    "        try: \n",
    "            if len(self.matrix) != len(matrix) or len(self.matrix) != len(matrix):\n",
    "                return 'e'\n",
    "            result = [[0 for j in range(len(matrix[0]))]\n",
    "                    for i in range(len(self.matrix))]\n",
    "            for i in range(len(self.matrix)):\n",
    "                for j in range(len(self.matrix[0])):\n",
    "                    result[i][j] = self.matrix[i][j] + matrix[i][j]\n",
    "            return result\n",
    "        except TypeError:\n",
    "            return 'e'\n",
    "\n",
    "    def getSummarize(self, matrix):\n",
    "        return self.get_readable_matrix_string(self.summarize(matrix))\n",
    "\n",
    "    def subtract(self, matrix):\n",
    "        try:\n",
    "            if len(self.matrix) != len(matrix) or len(self.matrix) != len(matrix):\n",
    "                return 'e'\n",
    "            result = [[0 for j in range(len(matrix[0]))]\n",
    "                    for i in range(len(self.matrix))]\n",
    "            for i in range(len(self.matrix)):\n",
    "                for j in range(len(self.matrix[0])):\n",
    "                    result[i][j] = self.matrix[i][j] - matrix[i][j]\n",
    "            return result\n",
    "        except TypeError:\n",
    "            return 'e'\n",
    "        \n",
    "\n",
    "    def getSubtraction(self, matrix):\n",
    "        return self.get_readable_matrix_string(self.subtract(matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9359de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LogisticRegression:\n",
    "#     def __init__(self, x, y):\n",
    "#         self.intercept = np.ones((x.shape[0], 1), dtype=float)\n",
    "#         self.x = np.concatenate((self.intercept, x), axis=1)\n",
    "#         self.weight = np.zeros((self.x.shape[1], 569), dtype=float)\n",
    "#         self.y = y\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def mult(a, b):\n",
    "#         try:\n",
    "#             result = [[0 for j in range(len(b[i]))] #matrix\n",
    "#                     for i in range(len(a))] #self.matrix\n",
    "#             for i in range(len(a)):\n",
    "#                 for j in range(len(b[0])):\n",
    "#                     for k in range(len(a)):\n",
    "#                         result[i][j] += float(b[i][k]) * float(a[k][j])\n",
    "#             return result\n",
    "#         except IndexError:\n",
    "#             return 'e'\n",
    "    \n",
    "    \n",
    "#     @staticmethod\n",
    "#     def sigmoid(self, x, weight):\n",
    "#         z = self.mult(x, weight)\n",
    "#         sigma = 1 / (1 + np.exp(z))\n",
    "#         return sigma\n",
    "    \n",
    "#     def loss(self, y):\n",
    "#         n = y.shape[0]\n",
    "#         h = self.sigmoid(self.x, self.weight)\n",
    "#         if True:\n",
    "#             try:\n",
    "#                 los = 1 / n * (-y.T * np.log(h) - (1 - y).T * np.log(1 - h))\n",
    "#                 return los\n",
    "#             except ValueError:\n",
    "#                 print('e')\n",
    "    \n",
    "#     def gradient_descent(self, y):\n",
    "#         n = y.shape[0]\n",
    "#         grad = 1 / n * self.x.transpose() @(self.sigmoid(self.x, self.weight) - y)\n",
    "#         return grad\n",
    "\n",
    "#     def fit(self, lr, iterations):\n",
    "#         for i in range(iterations):\n",
    "#             dw = self.gradient_descent(self.y)\n",
    "#             self.weight -= lr * dw\n",
    "        \n",
    "#         return print('Done')\n",
    "    \n",
    "# #     def predict(self, x, x_new, treshold):\n",
    "# #         x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "# #         result = self.sigmoid(x_new, self.weight)\n",
    "# #         result = result >= treshold\n",
    "# #         ypred = np.zeros(result.shape[0])\n",
    "# #         for i in range(len(ypred)):\n",
    "# #             if result[i]:\n",
    "# #                 ypred[i] = 1\n",
    "# #             else:\n",
    "# #                 continue\n",
    "# #         return ypred\n",
    "    \n",
    "#     def predict(self, x_new , treshold):\n",
    "#         x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "#         result = self.sigmoid(x_new, self.weight)\n",
    "#         result = result >= treshold\n",
    "#         y_pred = np.zeros(result.shape[0],31)\n",
    "#         for i in range(30):\n",
    "#             if result[i].any():\n",
    "#                 ypred[i] = 1\n",
    "#             else:\n",
    "#                 continue\n",
    "#         return y_pred\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b5296912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_breast_cancer()\n",
    "# a = data.data\n",
    "# b = data.target\n",
    "\n",
    "# regressor = LogisticRegression(a, b)\n",
    "# regressor.fit(0.1, 2)\n",
    "# y_pred = regressor.predict(a, 0.5)\n",
    "# result_accuracy = sum(y_pred, b.shape) / b.shape - 0.15\n",
    "# print('Accuracy => {}'.format(result_accuracy[0]))\n",
    "# start_time = datetime.now()\n",
    "# time.sleep(5)\n",
    "# print(datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1edf647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mult(a, b):\n",
    "#         try:\n",
    "#             result = [[0 for _ in range(b.shape[1])] for _ in range(a.shape[0])]\n",
    "#             for i in range(a.shape[0]):\n",
    "#                 for k in range(b.shape[1]):\n",
    "#                     for j in range(a.shape[1]):\n",
    "#                         result += float(a[i][j]) * float(b[j][k])\n",
    "#             return result\n",
    "#         except IndexError:\n",
    "#             return 'e'\n",
    "\n",
    "def mult(c, d):\n",
    "    res = [[0 for _ in range(d.shape[1])] for _ in range(c.shape[0])]\n",
    "    if c.shape[1] == d.shape[0]:\n",
    "        if True:\n",
    "            try:\n",
    "                for i in range(c.shape[0]):\n",
    "                    for k in range()\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, x, y):\n",
    "        self.intercept = np.ones((x.shape[0], 1))\n",
    "        self.x = np.concatenate((self.intercept, x), axis=1)\n",
    "        self.weight = np.zeros(self.x.shape[1])\n",
    "        self.y = y\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x, weight):\n",
    "#         z = mult(x, weight)\n",
    "        sigma = 1 / (1 + pow(math.e, mult(x, weight)))\n",
    "#         sigma = 1 / (1 + np.exp(mult(x, weight)))\n",
    "        return sigma\n",
    "    \n",
    "    def loss(self, y):\n",
    "        n = y.shape[0]\n",
    "        h = self.sigmoid(self.x, self.weight)\n",
    "        if True:\n",
    "            try:\n",
    "                los = 1 / n * (-y.T * np.log(h) - (1 - y).T * np.log(1 - h))\n",
    "                return los\n",
    "            except ValueError:\n",
    "                print('e')\n",
    "    \n",
    "    def gradient_descent(self, y):\n",
    "        n = y.shape[0]\n",
    "        grad = 1 / n * self.x.transpose() @(self.sigmoid(self.x, self.weight) - y)\n",
    "        return grad\n",
    "\n",
    "    def fit(self, lr, iterations):\n",
    "        for i in range(iterations):\n",
    "            dw = self.gradient_descent(self.y)\n",
    "            self.weight -= np.dot(lr, dw)\n",
    "        \n",
    "        return print('Done')\n",
    "    \n",
    "#     def predict(self, x, x_new, treshold):\n",
    "#         x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "#         result = self.sigmoid(x_new, self.weight)\n",
    "#         result = result >= treshold\n",
    "#         ypred = np.zeros(result.shape[0])\n",
    "#         for i in range(len(ypred)):\n",
    "#             if result[i]:\n",
    "#                 ypred[i] = 1\n",
    "#             else:\n",
    "#                 continue\n",
    "#         return ypred\n",
    "    \n",
    "    def predict(self, x_new , treshold):\n",
    "        x_new = np.concatenate((self.intercept, x_new), axis=1)\n",
    "        result = self.sigmoid(x_new, self.weight)\n",
    "        result = result >= treshold\n",
    "        y_pred = np.zeros(result.shape[0])\n",
    "        for i in range(len(y_pred)):\n",
    "            if result[i] == True:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                continue\n",
    "        return y_pred\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65ad02a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [65], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m b \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mtarget\n\u001b[1;32m      5\u001b[0m regressor \u001b[38;5;241m=\u001b[39m LogisticRegression(a, b)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mpredict(a, \u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m      8\u001b[0m result_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(y_pred, b\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m/\u001b[39m b\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.15\u001b[39m\n",
      "Cell \u001b[0;32mIn [64], line 44\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, lr, iterations)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, lr, iterations):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iterations):\n\u001b[0;32m---> 44\u001b[0m         dw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(lr, dw)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [64], line 39\u001b[0m, in \u001b[0;36mLogisticRegression.gradient_descent\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgradient_descent\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[1;32m     38\u001b[0m     n \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 39\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m n \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mtranspose() \u001b[38;5;241m@\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigmoid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m y)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "Cell \u001b[0;32mIn [64], line 23\u001b[0m, in \u001b[0;36mLogisticRegression.sigmoid\u001b[0;34m(x, weight)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid\u001b[39m(x, weight):\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#         z = mult(x, weight)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m         sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         sigma = 1 / (1 + np.exp(mult(x, weight)))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m sigma\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "a = data.data\n",
    "b = data.target\n",
    "\n",
    "regressor = LogisticRegression(a, b)\n",
    "regressor.fit(0.1, 2)\n",
    "y_pred = regressor.predict(a, 0.5)\n",
    "result_accuracy = sum(y_pred, b.shape) / b.shape - 0.15\n",
    "print('Accuracy => {}'.format(result_accuracy[0]))\n",
    "start_time = datetime.now()\n",
    "time.sleep(5)\n",
    "print(datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88050e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b5f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f459ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
